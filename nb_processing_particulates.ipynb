{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: this script uses a slightly different method of assigning labels to data since the labels were collected differently than in the pilot study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import datetime\n",
    "import geopandas\n",
    "import glob\n",
    "import pandas\n",
    "import shapely\n",
    "import tqdm.auto as tqdm\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map projections\n",
    "WGS84 = {\"init\": \"epsg:4326\"}\n",
    "WEB_MERCATOR = {\"init\": \"epsg:3857\"}\n",
    "NAD83_MA_FEET = {\"init\": \"epsg:2249\"}\n",
    "\n",
    "# basemap constants\n",
    "ESRI_WORLD_IMAGERY = \"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\"\n",
    "BASEMAP_ZOOM = 13\n",
    "\n",
    "# time adjustments\n",
    "PM_TIME_ADJUSTMENTS = collections.defaultdict(lambda: pandas.Timedelta(0), {\n",
    "    \"2019-10-27\": - pandas.Timedelta(\"5 minutes\") # there was a 5 minute drift in the PM sensor clock on this day\n",
    "})\n",
    "TZ_ADJUST_EASTERN_TIME = - pandas.Timedelta(\"5 hours\") # GMT -5:00:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the geometries that we have created earlier\n",
    "\n",
    "data will be joined against these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_stations = geopandas.read_file(\"./analysis/geometries/stations.geojson\")\n",
    "gdf_segments = geopandas.read_file(\"./analysis/geometries/segments.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a sampling date in yyyy-mm-dd format,\n",
    "# 1) load the relevant timestamps and particulate readings (may have to merge multiple files)\n",
    "# 2) perform necessary time adjustments:\n",
    "#     * label timestamps are loaded as EST\n",
    "#     * Dylos timestamps are loaded as GMT and must be converted to EST\n",
    "# 3) return the relevant data\n",
    "def read_data(sampling_date):\n",
    "    subdir = \"./data/%s\" % sampling_date\n",
    "\n",
    "    timestamps = pandas.read_csv(\"%s/timestamps.csv\" % subdir)\n",
    "    timestamps[\"TIME\"] = pandas.to_datetime(timestamps[\"TIME\"]) # tz-aware\n",
    "\n",
    "    pm_readings = pandas.concat([\n",
    "        pandas.read_csv(path)\n",
    "        for path in glob.glob(\"%s/dylos*.csv\" % subdir)\n",
    "    ])\n",
    "    pm_readings[\"TIME\"] = pandas.to_datetime(pm_readings[\"TIME\"], unit = \"s\")\\\n",
    "        + PM_TIME_ADJUSTMENTS[sampling_date] + TZ_ADJUST_EASTERN_TIME # not tz-aware: timezone must be applied\n",
    "    \n",
    "    return (timestamps, pm_readings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7601406f0edb4697bc6f69f1e9679acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_timestamps = []\n",
    "all_pm_readings = []\n",
    "\n",
    "for data_dir in tqdm.tqdm(glob.glob(\"./data/2019*\")):\n",
    "    day = data_dir.split(\"/\")[-1]\n",
    "    try:\n",
    "        (timestamps, pm_readings) = read_data(day)\n",
    "        all_timestamps.append(timestamps)\n",
    "        all_pm_readings.append(pm_readings)\n",
    "    except Exception as error:\n",
    "        print(\"ERROR: could not load %s\" % data_dir)\n",
    "        print(error)\n",
    "\n",
    "timestamps = pandas.concat(all_timestamps)\n",
    "pm_readings = pandas.concat(all_pm_readings)\n",
    "\n",
    "# * SMALLPARTICLES = all particles >= 0.5 microns\n",
    "# * LARGEPARTICLES = all particles >= 2.5 microns\n",
    "# so, we can get a rough proxy of PM2.5 by subtracting LARGEPARTICLES from SMALLPARTICLES\n",
    "pm_readings[\"SMALLPARTICLES\"] = pm_readings[\"SMALLPARTICLES\"] - pm_readings[\"LARGEPARTICLES\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label data with track geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: if an arrival or departure is dropped, label the next thing correctly\n",
    "# e.g. missed departure from station A: should not label A->B\n",
    "# possible fix: check STATUS column (Arrived/Left/Passed)\n",
    "\n",
    "# given a timestamps dataframe and pm_readings, group the data by station/segment\n",
    "# data is first labeled by joining pm timestamps to label time ranges\n",
    "# data is then joined to the geometries created earlier by using those labels\n",
    "def label_data(timestamps, pm_readings):\n",
    "    last_location = None\n",
    "    last_timestamp = None\n",
    "\n",
    "    pm_stations = []\n",
    "    pm_segments = []\n",
    "\n",
    "    for (index, row) in tqdm.tqdm(timestamps.iterrows(), total = timestamps.shape[0]):#timestamps.iterrows():\n",
    "        this_location = row[\"LOCATION\"]\n",
    "        this_timestamp = row[\"TIME\"]\n",
    "\n",
    "        if ((row[\"TIME\"] == None) or (row[\"LOCATION\"] == \"END\")):\n",
    "            last_location = None\n",
    "            last_timestamp = None\n",
    "            continue\n",
    "\n",
    "        if (last_timestamp is not None):\n",
    "\n",
    "            # pull out the relevant pm readings by subsetting on timestamps\n",
    "            pm_subset = pm_readings[\n",
    "                (pm_readings[\"TIME\"] >= last_timestamp)\n",
    "                & (pm_readings[\"TIME\"] < this_timestamp)\n",
    "            ].copy()\n",
    "            pm_subset[\"DIRECTION\"] = int(row[\"DIRECTION\"])\n",
    "\n",
    "            # this row is a station if the last two labels are the same\n",
    "            if (last_location == this_location):\n",
    "                station = gdf_stations[\n",
    "                    gdf_stations[\"ROUTE\"].apply(lambda route: row[\"ROUTE\"] in route)\n",
    "                    & (gdf_stations[\"STATION\"] == this_location)\n",
    "                ]\n",
    "\n",
    "                # append to pm_stations array; this will be used to build a dataframe\n",
    "                if ((station is None) or (len(station) == 0)):\n",
    "                    print(\"could not match station to shapefile: %s\" % this_location)\n",
    "                else:\n",
    "                    pm_subset[\"station_idx\"] = station.index[0]\n",
    "                    pm_stations.append(pm_subset)\n",
    "\n",
    "            # otherwise this row is a track segment\n",
    "            else:\n",
    "                gdf_possible_segments = gdf_segments[\n",
    "                    gdf_segments[\"ROUTE\"].apply(lambda route: row[\"ROUTE\"] in route)\n",
    "                ]\n",
    "                assert (gdf_possible_segments is not None)\n",
    "                segment = gdf_possible_segments[\n",
    "                    (gdf_possible_segments[\"START_STATION\"] == last_location)\n",
    "                    & (gdf_possible_segments[\"END_STATION\"] == this_location)\n",
    "                ]\n",
    "                #if (len(segment) > 0):\n",
    "                #    direction = 1\n",
    "                #else:\n",
    "                if len(segment) == 0:\n",
    "                    segment = gdf_possible_segments[\n",
    "                        (gdf_possible_segments[\"END_STATION\"] == last_location)\n",
    "                        & (gdf_possible_segments[\"START_STATION\"] == this_location)\n",
    "                    ]\n",
    "                    #direction = -1\n",
    "\n",
    "                # append to pm_segments array; this will be used to build a dataframe\n",
    "                if ((segment is None) or (len(segment) == 0)):\n",
    "                    print(\"could not match segment to shapefile: %s -> %s\" % (last_location, this_location))\n",
    "                else:\n",
    "                    pm_subset[\"segment_idx\"] = segment.index[0]\n",
    "                    #pm_subset[\"direction\"] = direction\n",
    "                    pm_segments.append(pm_subset)\n",
    "\n",
    "        last_location = this_location\n",
    "        last_timestamp = this_timestamp\n",
    "\n",
    "    gdf_pm_segments = pandas.merge(\n",
    "        pandas.concat(pm_segments),\n",
    "        gdf_segments,\n",
    "        left_on = \"segment_idx\",\n",
    "        right_index = True\n",
    "    )\n",
    "    gdf_pm_segments.crs = gdf_segments.crs\n",
    "    gdf_pm_stations = pandas.merge(\n",
    "        pandas.concat(pm_stations),\n",
    "        gdf_stations,\n",
    "        left_on = \"station_idx\",\n",
    "        right_index = True\n",
    "    )\n",
    "    gdf_pm_stations.crs = gdf_stations.crs\n",
    "    return (gdf_pm_segments, gdf_pm_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bafa05fa4946c897f19978133e9311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not match segment to shapefile: Pleasant Street -> Boston University Central\n",
      "could not match segment to shapefile: Wellington -> Sullivan Square\n",
      "could not match segment to shapefile: Wellington -> Sullivan Square\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(gdf_pm_segments, gdf_pm_stations) = label_data(timestamps, pm_readings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>SMALLPARTICLES</th>\n",
       "      <th>LARGEPARTICLES</th>\n",
       "      <th>DIRECTION</th>\n",
       "      <th>station_idx</th>\n",
       "      <th>STATION</th>\n",
       "      <th>LINE</th>\n",
       "      <th>ROUTE</th>\n",
       "      <th>TERMINUS</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-05 22:02:00</td>\n",
       "      <td>1903</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>Government Center</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>N</td>\n",
       "      <td>POINT (236291.822 901071.152)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2019-11-05 22:47:00</td>\n",
       "      <td>6395</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>Government Center</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>N</td>\n",
       "      <td>POINT (236291.822 901071.152)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2019-11-05 23:39:00</td>\n",
       "      <td>4309</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>Government Center</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>N</td>\n",
       "      <td>POINT (236291.822 901071.152)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  TIME  SMALLPARTICLES  LARGEPARTICLES  DIRECTION  \\\n",
       "4  2019-11-05 22:02:00            1903             109          0   \n",
       "41 2019-11-05 22:47:00            6395             255          1   \n",
       "82 2019-11-05 23:39:00            4309              74          1   \n",
       "\n",
       "    station_idx            STATION  LINE ROUTE TERMINUS  \\\n",
       "4            48  Government Center  Blue  Blue        N   \n",
       "41           48  Government Center  Blue  Blue        N   \n",
       "82           48  Government Center  Blue  Blue        N   \n",
       "\n",
       "                         geometry  \n",
       "4   POINT (236291.822 901071.152)  \n",
       "41  POINT (236291.822 901071.152)  \n",
       "82  POINT (236291.822 901071.152)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_pm_stations.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_time_category(time):\n",
    "    day = time.dayofweek\n",
    "    hour = time.hour\n",
    "    if (\n",
    "        (day == 0) # monday\n",
    "        and (hour >= 6) # after 6am\n",
    "        and (hour <= 9) # before 9am\n",
    "    ):\n",
    "        return \"rush_hour\"\n",
    "    elif (\n",
    "        (\n",
    "            (day in {6, 1, 2}) # sunday / tuesday / wednesday\n",
    "            and (hour >= 12+10) # after 10pm\n",
    "        )\n",
    "        or ( # OR\n",
    "            (day == 2) # wednesday\n",
    "            and (hour >= 10) # after 10am\n",
    "            and (hour <= 12+2) # before 2pm\n",
    "        )\n",
    "    ):\n",
    "        return \"off_peak\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_pm_segments[\"load\"] = gdf_pm_segments[\"TIME\"].apply(label_time_category)\n",
    "gdf_pm_stations[\"load\"] = gdf_pm_stations[\"TIME\"].apply(label_time_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>SMALLPARTICLES</th>\n",
       "      <th>LARGEPARTICLES</th>\n",
       "      <th>DIRECTION</th>\n",
       "      <th>segment_idx</th>\n",
       "      <th>LINE</th>\n",
       "      <th>ROUTE</th>\n",
       "      <th>START_STATION</th>\n",
       "      <th>END_STATION</th>\n",
       "      <th>length</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>geometry</th>\n",
       "      <th>load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-11-05 22:03:00</td>\n",
       "      <td>1373</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Government Center</td>\n",
       "      <td>State</td>\n",
       "      <td>147.582994</td>\n",
       "      <td>7</td>\n",
       "      <td>LINESTRING (236291.822 901071.152, 236298.589 ...</td>\n",
       "      <td>off_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019-11-05 22:46:00</td>\n",
       "      <td>6432</td>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Government Center</td>\n",
       "      <td>State</td>\n",
       "      <td>147.582994</td>\n",
       "      <td>7</td>\n",
       "      <td>LINESTRING (236291.822 901071.152, 236298.589 ...</td>\n",
       "      <td>off_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2019-11-05 22:54:00</td>\n",
       "      <td>1052</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Government Center</td>\n",
       "      <td>State</td>\n",
       "      <td>147.582994</td>\n",
       "      <td>7</td>\n",
       "      <td>LINESTRING (236291.822 901071.152, 236298.589 ...</td>\n",
       "      <td>off_peak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  TIME  SMALLPARTICLES  LARGEPARTICLES  DIRECTION  \\\n",
       "5  2019-11-05 22:03:00            1373              31          0   \n",
       "40 2019-11-05 22:46:00            6432             176          1   \n",
       "44 2019-11-05 22:54:00            1052              24          0   \n",
       "\n",
       "    segment_idx  LINE ROUTE      START_STATION END_STATION      length GRADE  \\\n",
       "5             4  Blue  Blue  Government Center       State  147.582994     7   \n",
       "40            4  Blue  Blue  Government Center       State  147.582994     7   \n",
       "44            4  Blue  Blue  Government Center       State  147.582994     7   \n",
       "\n",
       "                                             geometry      load  \n",
       "5   LINESTRING (236291.822 901071.152, 236298.589 ...  off_peak  \n",
       "40  LINESTRING (236291.822 901071.152, 236298.589 ...  off_peak  \n",
       "44  LINESTRING (236291.822 901071.152, 236298.589 ...  off_peak  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_pm_segments.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregations and file exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM_AGGREGATES = {\n",
    "    \"SMALLPARTICLES\": [\"median\", \"mean\", \"max\", \"std\", \"count\"],\n",
    "    \"LARGEPARTICLES\": [\"median\", \"mean\", \"max\", \"std\", \"count\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.export_all_aggregates(gdf_pm_stations, gdf_pm_segments, PM_AGGREGATES, \"particulates\")\n",
    "for load in [\"rush_hour\", \"off_peak\"]:\n",
    "    lib.export_all_aggregates(\n",
    "        gdf_pm_stations[gdf_pm_stations[\"load\"] == load],\n",
    "        gdf_pm_segments[gdf_pm_segments[\"load\"] == load],\n",
    "        PM_AGGREGATES,\n",
    "        \"particulates_{}\".format(load)\n",
    "    )\n",
    "\n",
    "for (particle_size, extra_info) in [\n",
    "    (\"small\", \" (PM2.5 Proxy)\"),\n",
    "    (\"large\", \"\")\n",
    "]:\n",
    "    quantity = \"{}PARTICLES\".format(particle_size.upper())\n",
    "    center = \"{}.mean\".format(quantity)\n",
    "    variability = \"{}.std\".format(quantity)\n",
    "    for (load, label_text) in [\n",
    "        (\"rush_hour\", \"rush hour\"),\n",
    "        (\"off_peak\", \"late night\")\n",
    "    ]:\n",
    "        stations = gdf_pm_stations[gdf_pm_stations[\"load\"] == load]\n",
    "        segments = gdf_pm_segments[gdf_pm_segments[\"load\"] == load]\n",
    "        quantity_name = \"particulates_{}_{}\".format(load, particle_size)\n",
    "        lib.export_webapp_input(\n",
    "            stations, segments,\n",
    "            aggregates=PM_AGGREGATES,\n",
    "            value_generators={\n",
    "                \"center\": lambda row: row[center],\n",
    "                \"upper\": lambda row: (row[center] + row[variability])\n",
    "                    if pandas.notnull(row[variability])\n",
    "                    else row[center],\n",
    "                \"lower\": lambda row: (row[center] - row[variability])\n",
    "                    if pandas.notnull(row[variability])\n",
    "                    else row[center],\n",
    "            },\n",
    "            metadata={\n",
    "                \"axis\": \"{} Particles{} [count/ft³]\"\\\n",
    "                    .format(particle_size.capitalize(), extra_info),\n",
    "                \"selection\": \"{} particles ({})\"\\\n",
    "                    .format(particle_size, load.replace(\"_\", \" \")),\n",
    "                \"center_desc\": \"Mean\",\n",
    "                \"variability_desc\": \"Mean ± 1SD\",\n",
    "                \"colormap\": \"viridis\"\n",
    "            },\n",
    "            quantity=quantity_name\n",
    "        )\n",
    "        lib.export_webapp_histograms(\n",
    "            stations, segments, quantity, quantity_name, 30\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_pm_segments.drop(\"geometry\", axis=1).to_csv(\"output/segments_particulates_new_rawdata.csv\", index=False)\n",
    "gdf_pm_stations.drop(\"geometry\", axis=1).to_csv(\"output/stations_particulates_new_rawdata\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
